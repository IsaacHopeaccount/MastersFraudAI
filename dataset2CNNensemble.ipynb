{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo']\n",
      "Number of features after preprocessing: 431\n",
      "Initial new_shape: (21, 21, 1)\n",
      "Padded features to match new_shape with padding size: 10\n",
      "Epoch 1/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step\n",
      "\n",
      "Epoch 1 - Best Threshold: 0.7970\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    142469\n",
      "           1       0.40      0.39      0.39      5166\n",
      "\n",
      "    accuracy                           0.96    147635\n",
      "   macro avg       0.69      0.68      0.69    147635\n",
      "weighted avg       0.96      0.96      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 6ms/step - accuracy: 0.7504 - loss: 0.5198 - val_accuracy: 0.8245 - val_loss: 0.4201\n",
      "Epoch 2/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step\n",
      "\n",
      "Epoch 2 - Best Threshold: 0.8405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    142469\n",
      "           1       0.43      0.41      0.42      5166\n",
      "\n",
      "    accuracy                           0.96    147635\n",
      "   macro avg       0.71      0.69      0.70    147635\n",
      "weighted avg       0.96      0.96      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 9ms/step - accuracy: 0.7972 - loss: 0.4528 - val_accuracy: 0.8323 - val_loss: 0.4098\n",
      "Epoch 3/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step\n",
      "\n",
      "Epoch 3 - Best Threshold: 0.7960\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    142469\n",
      "           1       0.44      0.41      0.42      5166\n",
      "\n",
      "    accuracy                           0.96    147635\n",
      "   macro avg       0.71      0.69      0.70    147635\n",
      "weighted avg       0.96      0.96      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 9ms/step - accuracy: 0.8082 - loss: 0.4330 - val_accuracy: 0.8343 - val_loss: 0.3980\n",
      "Epoch 4/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step\n",
      "\n",
      "Epoch 4 - Best Threshold: 0.7931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    142469\n",
      "           1       0.47      0.43      0.45      5166\n",
      "\n",
      "    accuracy                           0.96    147635\n",
      "   macro avg       0.72      0.71      0.71    147635\n",
      "weighted avg       0.96      0.96      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 9ms/step - accuracy: 0.8137 - loss: 0.4235 - val_accuracy: 0.8597 - val_loss: 0.3554\n",
      "Epoch 5/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step\n",
      "\n",
      "Epoch 5 - Best Threshold: 0.8153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    142469\n",
      "           1       0.49      0.41      0.45      5166\n",
      "\n",
      "    accuracy                           0.96    147635\n",
      "   macro avg       0.73      0.70      0.71    147635\n",
      "weighted avg       0.96      0.96      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 9ms/step - accuracy: 0.8174 - loss: 0.4183 - val_accuracy: 0.8533 - val_loss: 0.3695\n",
      "Epoch 6/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
      "\n",
      "Epoch 6 - Best Threshold: 0.8054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    142469\n",
      "           1       0.50      0.41      0.45      5166\n",
      "\n",
      "    accuracy                           0.96    147635\n",
      "   macro avg       0.74      0.70      0.72    147635\n",
      "weighted avg       0.96      0.96      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7ms/step - accuracy: 0.8201 - loss: 0.4113 - val_accuracy: 0.8593 - val_loss: 0.3619\n",
      "Epoch 7/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
      "\n",
      "Epoch 7 - Best Threshold: 0.8142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.52      0.41      0.46      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.75      0.70      0.72    147635\n",
      "weighted avg       0.96      0.97      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4027 - val_accuracy: 0.8558 - val_loss: 0.3530\n",
      "Epoch 8/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "\n",
      "Epoch 8 - Best Threshold: 0.8088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    142469\n",
      "           1       0.48      0.43      0.46      5166\n",
      "\n",
      "    accuracy                           0.96    147635\n",
      "   macro avg       0.73      0.71      0.72    147635\n",
      "weighted avg       0.96      0.96      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.4012 - val_accuracy: 0.8495 - val_loss: 0.3554\n",
      "Epoch 9/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
      "\n",
      "Epoch 9 - Best Threshold: 0.7647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    142469\n",
      "           1       0.49      0.44      0.46      5166\n",
      "\n",
      "    accuracy                           0.96    147635\n",
      "   macro avg       0.73      0.71      0.72    147635\n",
      "weighted avg       0.96      0.96      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4ms/step - accuracy: 0.8267 - loss: 0.3979 - val_accuracy: 0.8663 - val_loss: 0.3387\n",
      "Epoch 10/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
      "\n",
      "Epoch 10 - Best Threshold: 0.8045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.51      0.42      0.46      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.74      0.70      0.72    147635\n",
      "weighted avg       0.96      0.97      0.96    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.3945 - val_accuracy: 0.8642 - val_loss: 0.3530\n",
      "Epoch 11/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "\n",
      "Epoch 11 - Best Threshold: 0.8369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.57      0.40      0.47      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.78      0.69      0.73    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.3923 - val_accuracy: 0.8648 - val_loss: 0.3314\n",
      "Epoch 12/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 955us/step\n",
      "\n",
      "Epoch 12 - Best Threshold: 0.8447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.52      0.44      0.48      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.75      0.71      0.73    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.3914 - val_accuracy: 0.8511 - val_loss: 0.3793\n",
      "Epoch 13/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 984us/step\n",
      "\n",
      "Epoch 13 - Best Threshold: 0.8572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.56      0.41      0.48      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.77      0.70      0.73    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.3887 - val_accuracy: 0.8723 - val_loss: 0.3190\n",
      "Epoch 14/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 969us/step\n",
      "\n",
      "Epoch 14 - Best Threshold: 0.8348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.55      0.43      0.48      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.77      0.71      0.73    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.3883 - val_accuracy: 0.8626 - val_loss: 0.3386\n",
      "Epoch 15/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 896us/step\n",
      "\n",
      "Epoch 15 - Best Threshold: 0.8131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.54      0.43      0.48      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.76      0.71      0.73    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3ms/step - accuracy: 0.8326 - loss: 0.3851 - val_accuracy: 0.8530 - val_loss: 0.3384\n",
      "Epoch 16/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 942us/step\n",
      "\n",
      "Epoch 16 - Best Threshold: 0.8568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.55      0.40      0.46      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.77      0.69      0.72    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.3840 - val_accuracy: 0.8732 - val_loss: 0.3329\n",
      "Epoch 17/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 951us/step\n",
      "\n",
      "Epoch 17 - Best Threshold: 0.8375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.57      0.41      0.48      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.78      0.70      0.73    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3ms/step - accuracy: 0.8349 - loss: 0.3837 - val_accuracy: 0.8766 - val_loss: 0.3265\n",
      "Epoch 18/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 973us/step\n",
      "\n",
      "Epoch 18 - Best Threshold: 0.7877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.56      0.43      0.49      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.77      0.71      0.73    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.3799 - val_accuracy: 0.8978 - val_loss: 0.3024\n",
      "Epoch 19/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 961us/step\n",
      "\n",
      "Epoch 19 - Best Threshold: 0.8153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.55      0.44      0.49      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.76      0.71      0.74    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3815 - val_accuracy: 0.8807 - val_loss: 0.3209\n",
      "Epoch 20/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 986us/step\n",
      "\n",
      "Epoch 20 - Best Threshold: 0.8014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.55      0.43      0.48      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.76      0.71      0.73    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.3807 - val_accuracy: 0.8854 - val_loss: 0.2929\n",
      "Epoch 21/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 955us/step\n",
      "\n",
      "Epoch 21 - Best Threshold: 0.8367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.57      0.42      0.49      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.77      0.71      0.74    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3798 - val_accuracy: 0.8756 - val_loss: 0.3347\n",
      "Epoch 22/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 905us/step\n",
      "\n",
      "Epoch 22 - Best Threshold: 0.8150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.60      0.42      0.49      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.79      0.70      0.74    147635\n",
      "weighted avg       0.97      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3785 - val_accuracy: 0.8903 - val_loss: 0.3099\n",
      "Epoch 23/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 901us/step\n",
      "\n",
      "Epoch 23 - Best Threshold: 0.8178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.55      0.44      0.49      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.77      0.71      0.74    147635\n",
      "weighted avg       0.96      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.3758 - val_accuracy: 0.8766 - val_loss: 0.3210\n",
      "Epoch 24/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 969us/step\n",
      "\n",
      "Epoch 24 - Best Threshold: 0.8158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.58      0.42      0.49      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.78      0.70      0.74    147635\n",
      "weighted avg       0.97      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3ms/step - accuracy: 0.8367 - loss: 0.3803 - val_accuracy: 0.8719 - val_loss: 0.3256\n",
      "Epoch 25/50\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 944us/step\n",
      "\n",
      "Epoch 25 - Best Threshold: 0.8221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    142469\n",
      "           1       0.57      0.43      0.49      5166\n",
      "\n",
      "    accuracy                           0.97    147635\n",
      "   macro avg       0.77      0.71      0.74    147635\n",
      "weighted avg       0.97      0.97      0.97    147635\n",
      "\n",
      "\u001b[1m18700/18700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3770 - val_accuracy: 0.8917 - val_loss: 0.3028\n",
      "Training fold 1...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 941us/step\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 936us/step\n",
      "Training fold 2...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 978us/step\n",
      "Training fold 3...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 959us/step\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 890us/step\n",
      "Training fold 4...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 962us/step\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 902us/step\n",
      "Training fold 5...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 932us/step\n",
      "\u001b[1m4614/4614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 933us/step\n",
      "\n",
      "Ensemble Model - Best Threshold: 0.1874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    142469\n",
      "           1       0.79      0.65      0.71      5166\n",
      "\n",
      "    accuracy                           0.98    147635\n",
      "   macro avg       0.89      0.82      0.85    147635\n",
      "weighted avg       0.98      0.98      0.98    147635\n",
      "\n",
      "Average Precision-Recall Score: 0.7337\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Load the datasets\n",
    "train_transactions = pd.read_csv('dataset2-ieee-fraud-detection/train_transaction.csv')\n",
    "train_identity = pd.read_csv('dataset2-ieee-fraud-detection/train_identity.csv')\n",
    "\n",
    "# Merge the datasets on 'TransactionID'\n",
    "train = pd.merge(train_transactions, train_identity, on='TransactionID', how='left')\n",
    "\n",
    "# Check and remove duplicate rows\n",
    "train.drop_duplicates(inplace=True)\n",
    "\n",
    "# Extract the target variable\n",
    "y = train['isFraud'].astype('uint8')\n",
    "\n",
    "# Drop columns not needed for modeling\n",
    "columns_to_drop = ['TransactionID', 'TransactionDT']\n",
    "train.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Handle missing values\n",
    "\n",
    "train.fillna(-999, inplace=True)\n",
    "\n",
    "# Handle categorical variables\n",
    "categorical_cols = train.select_dtypes(include=['object']).columns\n",
    "print(f\"Categorical columns: {categorical_cols.tolist()}\")\n",
    "\n",
    "# Apply Label Encoding to categorical variables\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col].astype(str))\n",
    "\n",
    "# Define features and target variable\n",
    "X = train.drop(columns=['isFraud'])\n",
    "y = train['isFraud'].astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(sampling_strategy=0.4, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_full_scaled, y_train_full)\n",
    "\n",
    "# Ensure y_train_resampled is a numpy array of int type\n",
    "y_train_resampled = np.array(y_train_resampled).astype(int)\n",
    "\n",
    "# Compute class weights for the full resampled training data\n",
    "class_weights_values = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_resampled),\n",
    "    y=y_train_resampled\n",
    ")\n",
    "class_weights = dict(zip(np.unique(y_train_resampled), class_weights_values))\n",
    "\n",
    "# Reshape data for CNN\n",
    "num_features = X_train_resampled.shape[1]\n",
    "print(f\"Number of features after preprocessing: {num_features}\")\n",
    "\n",
    "# Determine the new shape for CNN input\n",
    "side_length = int(np.ceil(np.sqrt(num_features)))\n",
    "new_shape = (side_length, side_length, 1)\n",
    "print(f\"Initial new_shape: {new_shape}\")\n",
    "\n",
    "# If necessary, pad the features with zeros to fit the new shape\n",
    "padding_size = (new_shape[0] * new_shape[1]) - num_features\n",
    "if padding_size > 0:\n",
    "    X_train_resampled = np.pad(\n",
    "        X_train_resampled, ((0, 0), (0, padding_size)), mode='constant'\n",
    "    )\n",
    "    X_test_scaled = np.pad(\n",
    "        X_test_scaled, ((0, 0), (0, padding_size)), mode='constant'\n",
    "    )\n",
    "    print(f\"Padded features to match new_shape with padding size: {padding_size}\")\n",
    "\n",
    "# Reshape the data\n",
    "X_train_resampled_cnn = X_train_resampled.reshape(-1, *new_shape)\n",
    "X_test_cnn = X_test_scaled.reshape(-1, *new_shape)\n",
    "\n",
    "# Define the custom callback for dynamic thresholding\n",
    "class DynamicThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_proba = self.model.predict(self.X_val).flatten()\n",
    "        precision, recall, thresholds = precision_recall_curve(self.y_val, y_proba)\n",
    "        f1_scores = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "        y_pred = (y_proba >= best_threshold).astype(int)\n",
    "        print(f\"\\nEpoch {epoch + 1} - Best Threshold: {best_threshold:.4f}\")\n",
    "        print(classification_report(self.y_val, y_pred))\n",
    "\n",
    "# Implement early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define CNN model with Input layer\n",
    "model_cnn = Sequential([\n",
    "    Input(shape=new_shape),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with class weights\n",
    "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train CNN model with the custom callback and early stopping\n",
    "model_cnn.fit(\n",
    "    X_train_resampled_cnn, y_train_resampled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_cnn, y_test),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[DynamicThresholdCallback(X_test_cnn, y_test), early_stopping]\n",
    ")\n",
    "\n",
    "# Train XGBoost model with adjusted scale_pos_weight\n",
    "scale_pos_weight = class_weights[0] / class_weights[1]\n",
    "\n",
    "clf_xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.2,\n",
    "    subsample=0.75,\n",
    "    colsample_bytree=0.75,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "clf_xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Generate meta-features using cross-validation\n",
    "meta_train = np.zeros((X_train_resampled.shape[0], 2))\n",
    "meta_test = np.zeros((X_test_scaled.shape[0], 2))\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_resampled, y_train_resampled)):\n",
    "    print(f\"Training fold {fold + 1}...\")\n",
    "    X_tr, X_val = X_train_resampled[train_idx], X_train_resampled[val_idx]\n",
    "    y_tr, y_val = y_train_resampled[train_idx], y_train_resampled[val_idx]\n",
    "\n",
    "    # Ensure y_tr and y_val are numpy arrays of int type\n",
    "    y_tr = np.array(y_tr).astype(int)\n",
    "    y_val = np.array(y_val).astype(int)\n",
    "\n",
    "    # Check unique classes in y_tr\n",
    "    unique_classes = np.unique(y_tr)\n",
    "    print(f\"Unique classes in y_tr: {unique_classes}\")\n",
    "\n",
    "    if len(unique_classes) < 2:\n",
    "        print(f\"Only one class present in y_tr for fold {fold + 1}. Skipping this fold.\")\n",
    "        continue\n",
    "\n",
    "    # Compute class weights for the current fold\n",
    "    class_weights_fold_values = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=unique_classes,\n",
    "        y=y_tr\n",
    "    )\n",
    "    class_weights_fold = dict(zip(unique_classes, class_weights_fold_values))\n",
    "\n",
    "    # Adjust scale_pos_weight for XGBoost\n",
    "    scale_pos_weight_fold = class_weights_fold[0] / class_weights_fold[1]\n",
    "\n",
    "    # Reshape data for CNN\n",
    "    X_tr_cnn = X_tr.reshape(-1, *new_shape)\n",
    "    X_val_cnn = X_val.reshape(-1, *new_shape)\n",
    "\n",
    "    # Train base models\n",
    "    # CNN model\n",
    "    model_cnn_fold = tf.keras.models.clone_model(model_cnn)\n",
    "    model_cnn_fold.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model_cnn_fold.fit(\n",
    "        X_tr_cnn, y_tr,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weights_fold,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # XGBoost model\n",
    "    clf_xgb_fold = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.2,\n",
    "        subsample=0.75,\n",
    "        colsample_bytree=0.75,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight_fold\n",
    "    )\n",
    "    clf_xgb_fold.fit(X_tr, y_tr)\n",
    "\n",
    "    # Predict on validation fold\n",
    "    cnn_val_preds = model_cnn_fold.predict(X_val_cnn).flatten()\n",
    "    xgb_val_preds = clf_xgb_fold.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Store predictions as meta-features\n",
    "    meta_train[val_idx, 0] = cnn_val_preds\n",
    "    meta_train[val_idx, 1] = xgb_val_preds\n",
    "\n",
    "    # Predict on test set and average\n",
    "    cnn_test_preds = model_cnn_fold.predict(X_test_cnn).flatten()\n",
    "    xgb_test_preds = clf_xgb_fold.predict_proba(X_test_scaled)[:, 1]\n",
    "    meta_test[:, 0] += cnn_test_preds / skf.n_splits\n",
    "    meta_test[:, 1] += xgb_test_preds / skf.n_splits\n",
    "\n",
    "# Ensure meta_train and meta_test are properly populated\n",
    "if np.any(np.isnan(meta_train)) or np.any(np.isnan(meta_test)):\n",
    "    print(\"NaN values found in meta features. Please check the cross-validation loop.\")\n",
    "else:\n",
    "    # Train meta-model\n",
    "    meta_model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "    meta_model.fit(meta_train, y_train_resampled)\n",
    "\n",
    "    # Evaluate the ensemble model\n",
    "    ensemble_proba = meta_model.predict_proba(meta_test)[:, 1]\n",
    "\n",
    "    # Find optimal threshold for ensemble model\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, ensemble_proba)\n",
    "    f1_scores = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "    ensemble_preds = (ensemble_proba >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\nEnsemble Model - Best Threshold: {best_threshold:.4f}\")\n",
    "    print(classification_report(y_test, ensemble_preds))\n",
    "\n",
    "    # Compute Average Precision Score\n",
    "    average_precision = average_precision_score(y_test, ensemble_proba)\n",
    "    print(f'Average Precision-Recall Score: {average_precision:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
