{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step\n",
      "\n",
      "Epoch 1 - Best Threshold: 0.9950\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.86      0.77      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.89      0.91     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.1872 - val_accuracy: 0.9867 - val_loss: 0.0655\n",
      "Epoch 2/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694us/step\n",
      "\n",
      "Epoch 2 - Best Threshold: 0.9982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.83      0.78      0.80       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.91      0.89      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.0926 - val_accuracy: 0.9834 - val_loss: 0.0609\n",
      "Epoch 3/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 691us/step\n",
      "\n",
      "Epoch 3 - Best Threshold: 0.9999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.87      0.75      0.80       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.94      0.87      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0784 - val_accuracy: 0.9872 - val_loss: 0.0488\n",
      "Epoch 4/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530us/step\n",
      "\n",
      "Epoch 4 - Best Threshold: 0.9998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.84      0.75      0.79       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.92      0.88      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0694 - val_accuracy: 0.9872 - val_loss: 0.0472\n",
      "Epoch 5/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step\n",
      "\n",
      "Epoch 5 - Best Threshold: 0.9980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.85      0.77      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.89      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9758 - loss: 0.0685 - val_accuracy: 0.9853 - val_loss: 0.0480\n",
      "Epoch 6/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step\n",
      "\n",
      "Epoch 6 - Best Threshold: 0.9995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.87      0.73      0.79       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.86      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0628 - val_accuracy: 0.9901 - val_loss: 0.0353\n",
      "Epoch 7/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step\n",
      "\n",
      "Epoch 7 - Best Threshold: 0.9997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.87      0.76      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.88      0.91     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9784 - loss: 0.0621 - val_accuracy: 0.9901 - val_loss: 0.0388\n",
      "Epoch 8/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step\n",
      "\n",
      "Epoch 8 - Best Threshold: 0.9998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.86      0.75      0.80       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.88      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9791 - loss: 0.0583 - val_accuracy: 0.9898 - val_loss: 0.0347\n",
      "Epoch 9/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step\n",
      "\n",
      "Epoch 9 - Best Threshold: 0.9879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.83      0.78      0.80       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.91      0.89      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9787 - loss: 0.0604 - val_accuracy: 0.9891 - val_loss: 0.0367\n",
      "Epoch 10/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step\n",
      "\n",
      "Epoch 10 - Best Threshold: 0.9999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.87      0.75      0.80       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.94      0.87      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9790 - loss: 0.0586 - val_accuracy: 0.9883 - val_loss: 0.0386\n",
      "Epoch 11/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step\n",
      "\n",
      "Epoch 11 - Best Threshold: 0.9978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.86      0.76      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.88      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - accuracy: 0.9794 - loss: 0.0577 - val_accuracy: 0.9928 - val_loss: 0.0275\n",
      "Epoch 12/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step\n",
      "\n",
      "Epoch 12 - Best Threshold: 0.9989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.86      0.76      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.88      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9796 - loss: 0.0566 - val_accuracy: 0.9885 - val_loss: 0.0382\n",
      "Epoch 13/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step\n",
      "\n",
      "Epoch 13 - Best Threshold: 0.9997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.87      0.76      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.88      0.91     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9796 - loss: 0.0566 - val_accuracy: 0.9900 - val_loss: 0.0359\n",
      "Epoch 14/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step\n",
      "\n",
      "Epoch 14 - Best Threshold: 0.9993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.86      0.76      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.88      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9803 - loss: 0.0552 - val_accuracy: 0.9893 - val_loss: 0.0365\n",
      "Epoch 15/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step\n",
      "\n",
      "Epoch 15 - Best Threshold: 0.9985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.86      0.76      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.88      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9802 - loss: 0.0565 - val_accuracy: 0.9901 - val_loss: 0.0341\n",
      "Epoch 16/50\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step\n",
      "\n",
      "Epoch 16 - Best Threshold: 0.9994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.86      0.76      0.81       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.93      0.88      0.90     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "\u001b[1m9959/9959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9801 - loss: 0.0559 - val_accuracy: 0.9907 - val_loss: 0.0339\n",
      "Training fold 1...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step\n",
      "Training fold 2...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step\n",
      "Training fold 3...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step\n",
      "Training fold 4...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step\n",
      "Training fold 5...\n",
      "Unique classes in y_tr: [0 1]\n",
      "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step\n",
      "\u001b[1m2217/2217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step\n",
      "\n",
      "Ensemble Model - Best Threshold: 0.9988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70814\n",
      "           1       0.96      0.77      0.85       118\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.98      0.89      0.93     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n",
      "Average Precision-Recall Score: 0.8142\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "dataset1 = pd.read_csv('dataset1-MLG/creditcard.csv')\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "\n",
    "# Ensure 'Time' and 'Amount' columns are numeric\n",
    "numeric_columns = ['Time', 'Amount']\n",
    "for col in numeric_columns:\n",
    "    dataset1[col] = pd.to_numeric(dataset1[col], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values\n",
    "dataset1.dropna(inplace=True)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = dataset1.drop(columns=['Class'])\n",
    "y = dataset1['Class'].astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance on training data\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_full_scaled, y_train_full)\n",
    "\n",
    "# Ensure y_train_resampled is a numpy array of int type\n",
    "y_train_resampled = np.array(y_train_resampled).astype(int)\n",
    "\n",
    "# Compute class weights for the full resampled training data\n",
    "class_weights_values = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_resampled),\n",
    "    y=y_train_resampled\n",
    ")\n",
    "class_weights = dict(zip(np.unique(y_train_resampled), class_weights_values))\n",
    "\n",
    "# Reshape data for CNN\n",
    "num_features = X_train_resampled.shape[1] \n",
    "new_shape = (5, 6, 1)  \n",
    "X_train_resampled_cnn = X_train_resampled.reshape(-1, *new_shape)\n",
    "X_test_cnn = X_test_scaled.reshape(-1, *new_shape)\n",
    "\n",
    "# Define the custom callback for dynamic thresholding\n",
    "class DynamicThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_proba = self.model.predict(self.X_val).flatten()\n",
    "        precision, recall, thresholds = precision_recall_curve(self.y_val, y_proba)\n",
    "        f1_scores = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "        y_pred = (y_proba >= best_threshold).astype(int)\n",
    "        print(f\"\\nEpoch {epoch + 1} - Best Threshold: {best_threshold:.4f}\")\n",
    "        print(classification_report(self.y_val, y_pred))\n",
    "\n",
    "# Implement early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define CNN model with Input layer\n",
    "model_cnn = Sequential([\n",
    "    Input(shape=new_shape),\n",
    "    Conv2D(32, (2, 2), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with class weights\n",
    "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train CNN model with the custom callback and early stopping\n",
    "model_cnn.fit(\n",
    "    X_train_resampled_cnn, y_train_resampled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_cnn, y_test),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[DynamicThresholdCallback(X_test_cnn, y_test), early_stopping]\n",
    ")\n",
    "\n",
    "# Train XGBoost model with adjusted scale_pos_weight\n",
    "scale_pos_weight = class_weights[0] / class_weights[1]\n",
    "\n",
    "clf_xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.2,\n",
    "    subsample=0.75,\n",
    "    colsample_bytree=0.75,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "clf_xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Generate meta-features using cross-validation\n",
    "meta_train = np.zeros((X_train_resampled.shape[0], 2))\n",
    "meta_test = np.zeros((X_test_scaled.shape[0], 2))\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_resampled, y_train_resampled)):\n",
    "    print(f\"Training fold {fold + 1}...\")\n",
    "    X_tr, X_val = X_train_resampled[train_idx], X_train_resampled[val_idx]\n",
    "    y_tr, y_val = y_train_resampled[train_idx], y_train_resampled[val_idx]\n",
    "\n",
    "    # Ensure y_tr and y_val are numpy arrays of int type\n",
    "    y_tr = np.array(y_tr).astype(int)\n",
    "    y_val = np.array(y_val).astype(int)\n",
    "\n",
    "    # Check unique classes in y_tr\n",
    "    unique_classes = np.unique(y_tr)\n",
    "    print(f\"Unique classes in y_tr: {unique_classes}\")\n",
    "\n",
    "    if len(unique_classes) < 2:\n",
    "        print(f\"Only one class present in y_tr for fold {fold + 1}. Skipping this fold.\")\n",
    "        continue\n",
    "\n",
    "    # Compute class weights for the current fold\n",
    "    class_weights_fold_values = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=unique_classes,\n",
    "        y=y_tr\n",
    "    )\n",
    "    class_weights_fold = dict(zip(unique_classes, class_weights_fold_values))\n",
    "\n",
    "    # Adjust scale_pos_weight for XGBoost\n",
    "    scale_pos_weight_fold = class_weights_fold[0] / class_weights_fold[1]\n",
    "\n",
    "    # Reshape data for CNN\n",
    "    X_tr_cnn = X_tr.reshape(-1, *new_shape)\n",
    "    X_val_cnn = X_val.reshape(-1, *new_shape)\n",
    "\n",
    "    # Train base models\n",
    "    # CNN model\n",
    "    model_cnn_fold = tf.keras.models.clone_model(model_cnn)\n",
    "    model_cnn_fold.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model_cnn_fold.fit(\n",
    "        X_tr_cnn, y_tr,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weights_fold,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # XGBoost model\n",
    "    clf_xgb_fold = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.2,\n",
    "        subsample=0.75,\n",
    "        colsample_bytree=0.75,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight_fold\n",
    "    )\n",
    "    clf_xgb_fold.fit(X_tr, y_tr)\n",
    "\n",
    "    # Predict on validation fold\n",
    "    cnn_val_preds = model_cnn_fold.predict(X_val_cnn).flatten()\n",
    "    xgb_val_preds = clf_xgb_fold.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Store predictions as meta-features\n",
    "    meta_train[val_idx, 0] = cnn_val_preds\n",
    "    meta_train[val_idx, 1] = xgb_val_preds\n",
    "\n",
    "    # Predict on test set and average\n",
    "    cnn_test_preds = model_cnn_fold.predict(X_test_cnn).flatten()\n",
    "    xgb_test_preds = clf_xgb_fold.predict_proba(X_test_scaled)[:, 1]\n",
    "    meta_test[:, 0] += cnn_test_preds / skf.n_splits\n",
    "    meta_test[:, 1] += xgb_test_preds / skf.n_splits\n",
    "\n",
    "# Ensure meta_train and meta_test are properly populated\n",
    "if np.any(np.isnan(meta_train)) or np.any(np.isnan(meta_test)):\n",
    "    print(\"NaN values found in meta features. Please check the cross-validation loop.\")\n",
    "else:\n",
    "    # Train meta-model\n",
    "    meta_model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "    meta_model.fit(meta_train, y_train_resampled)\n",
    "\n",
    "    # Evaluate the ensemble model\n",
    "    ensemble_proba = meta_model.predict_proba(meta_test)[:, 1]\n",
    "\n",
    "    # Find optimal threshold for ensemble model\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, ensemble_proba)\n",
    "    f1_scores = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "    ensemble_preds = (ensemble_proba >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\nEnsemble Model - Best Threshold: {best_threshold:.4f}\")\n",
    "    print(classification_report(y_test, ensemble_preds))\n",
    "\n",
    "    # Compute Average Precision Score\n",
    "    average_precision = average_precision_score(y_test, ensemble_proba)\n",
    "    print(f'Average Precision-Recall Score: {average_precision:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
